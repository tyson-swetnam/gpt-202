{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"GPT 202: Introduction to ChatBots \u00b6 Welcome to our documentation on Generative Artificial Intelligence (AI) ChatBot creation in academic education and documentation. Learning Objectives After the lesson, you should be able to: * Understand the risks and benefits of fine tuning your own ChatBots * Create your own ChatBot using either OpenAI or open source APIs * Manage your own ChatBots running on Virtual Machines * Understand how and when to use AI assistants for education or documentation","title":"Home"},{"location":"#gpt-202-introduction-to-chatbots","text":"Welcome to our documentation on Generative Artificial Intelligence (AI) ChatBot creation in academic education and documentation. Learning Objectives After the lesson, you should be able to: * Understand the risks and benefits of fine tuning your own ChatBots * Create your own ChatBot using either OpenAI or open source APIs * Manage your own ChatBots running on Virtual Machines * Understand how and when to use AI assistants for education or documentation","title":"GPT 202: Introduction to ChatBots"},{"location":"about_gradio/","text":"Gradio Apps \u00b6","title":"About"},{"location":"about_gradio/#gradio-apps","text":"","title":"Gradio Apps"},{"location":"agenda/","text":"Agenda \u00b6 Instructors(s): \u00b6 Jeffrey Gillan PhD Carlos Liz\u00e1rraga-Celaya PhD Mith\u00fcn Paul PhD Tyson Lee Swetnam PhD Schedule \u00b6 Time Activity Instructor Links 08:30 Welcome All this website 08:40 Overview & Code of Conduct Tyson code of conduct 09:00 I. Introduction to Chatbots and Web APIs (20 minutes) Tyson RAG 09:20 II. OpenAI and OpenSource LLM Landscape (40 minutes) Tyson OpenAI , llama 10:00 Break All 10:10 III. Building Chatbots with Web APIs (60 minutes) Mithun 11:10 IV. Curating Knowledge Files for Chatbots (40 minutes) Carlos 11:50 V. Q&A Session (20 minutes) All 12:10 Lunch All 13:00 VI. Hands-on: Creating Chatbots (120 minutes) All 15:00 Break (20 minutes) All 15:20 VII. Presentation of Attendee ChatBots (80 minutes) Students 16:40 VIII. Q&A Session (20 minutes) All 17:00 Adjourn All Opportunity for participants to ask questions about the material covered in the workshop and provide feedback on the experience Closing remarks and resources for further exploration of the topic Pre-requisites \u00b6 a laptop with an active wifi connection Optional \u00b6 a personal GMail account (to access Bard - suggest using Chrome Browser ) Install the Microsoft Edge Browser for using Microsoft Bing w/ Chat ChatGPT Plus account OpenAI API account Code of Conduct \u00b6 This Code of Conduct applies to all Event participants, instructors, and activities during the workshop. Data Science Institute (DSI) is dedicated to providing professional computational research and educational experiences for all of our users, regardless of domain focus, academic status, educational level, gender/gender identity/expression, age, sexual orientation, mental or physical ability, physical appearance, body size, race, ethnicity, religion (or lack thereof), technology choices, dietary preferences, or any other personal characteristic. While participating at an Event, we expect you to: Interact with others and use ChatGPT professionally and ethically by complying with our Policies. Constructively critize ideas and processes, not people. Follow the Golden Rule (treat others as you want to be treated) when interacting online or in-person with collaborators, trainers, and support staff. Comply with this Code in spirit as much as the letter, as it is neither exhaustive nor complete in identifying any and all possible unacceptable conduct. We do not tolerate harassment of other users or staff in any form (including, but not limited to, violent threats or language, derogatory language or jokes, doxing, insults, advocating for or encouraging any of these behaviors). Sexual language and imagery are not appropriate at any time (excludes Protected Health Information in compliance with HIPAA). Any user violating this Code may be expelled from the platform and the workshop at DSI's sole discretion without warning. To report a violation of this Code, directly speak to a trainer. If you are not comfortable speaking to a trainer, or the trainer is who you are reporting, email info@cyverse.org with the following information: Your contact information Names (real, username, pseudonyms) of any individuals involved, and or witness(es) if any. Your account of what occurred and if the incident is ongoing. If there is a publicly available record (a tweet, public chat log, etc.), please include a link or attachment. Any additional information that may be helpful in resolving the issue.","title":"Workshop Agenda"},{"location":"agenda/#agenda","text":"","title":"Agenda"},{"location":"agenda/#instructorss","text":"Jeffrey Gillan PhD Carlos Liz\u00e1rraga-Celaya PhD Mith\u00fcn Paul PhD Tyson Lee Swetnam PhD","title":"Instructors(s):"},{"location":"agenda/#schedule","text":"Time Activity Instructor Links 08:30 Welcome All this website 08:40 Overview & Code of Conduct Tyson code of conduct 09:00 I. Introduction to Chatbots and Web APIs (20 minutes) Tyson RAG 09:20 II. OpenAI and OpenSource LLM Landscape (40 minutes) Tyson OpenAI , llama 10:00 Break All 10:10 III. Building Chatbots with Web APIs (60 minutes) Mithun 11:10 IV. Curating Knowledge Files for Chatbots (40 minutes) Carlos 11:50 V. Q&A Session (20 minutes) All 12:10 Lunch All 13:00 VI. Hands-on: Creating Chatbots (120 minutes) All 15:00 Break (20 minutes) All 15:20 VII. Presentation of Attendee ChatBots (80 minutes) Students 16:40 VIII. Q&A Session (20 minutes) All 17:00 Adjourn All Opportunity for participants to ask questions about the material covered in the workshop and provide feedback on the experience Closing remarks and resources for further exploration of the topic","title":"Schedule"},{"location":"agenda/#pre-requisites","text":"a laptop with an active wifi connection","title":"Pre-requisites"},{"location":"agenda/#optional","text":"a personal GMail account (to access Bard - suggest using Chrome Browser ) Install the Microsoft Edge Browser for using Microsoft Bing w/ Chat ChatGPT Plus account OpenAI API account","title":"Optional"},{"location":"agenda/#code-of-conduct","text":"This Code of Conduct applies to all Event participants, instructors, and activities during the workshop. Data Science Institute (DSI) is dedicated to providing professional computational research and educational experiences for all of our users, regardless of domain focus, academic status, educational level, gender/gender identity/expression, age, sexual orientation, mental or physical ability, physical appearance, body size, race, ethnicity, religion (or lack thereof), technology choices, dietary preferences, or any other personal characteristic. While participating at an Event, we expect you to: Interact with others and use ChatGPT professionally and ethically by complying with our Policies. Constructively critize ideas and processes, not people. Follow the Golden Rule (treat others as you want to be treated) when interacting online or in-person with collaborators, trainers, and support staff. Comply with this Code in spirit as much as the letter, as it is neither exhaustive nor complete in identifying any and all possible unacceptable conduct. We do not tolerate harassment of other users or staff in any form (including, but not limited to, violent threats or language, derogatory language or jokes, doxing, insults, advocating for or encouraging any of these behaviors). Sexual language and imagery are not appropriate at any time (excludes Protected Health Information in compliance with HIPAA). Any user violating this Code may be expelled from the platform and the workshop at DSI's sole discretion without warning. To report a violation of this Code, directly speak to a trainer. If you are not comfortable speaking to a trainer, or the trainer is who you are reporting, email info@cyverse.org with the following information: Your contact information Names (real, username, pseudonyms) of any individuals involved, and or witness(es) if any. Your account of what occurred and if the incident is ongoing. If there is a publicly available record (a tweet, public chat log, etc.), please include a link or attachment. Any additional information that may be helpful in resolving the issue.","title":"Code of Conduct"},{"location":"dify/","text":"Dify \u00b6 https://github.com/langgenius/dify","title":"Dify"},{"location":"dify/#dify","text":"https://github.com/langgenius/dify","title":"Dify"},{"location":"flowise/","text":"flowise \u00b6 https://flowiseai.com/","title":"Flowise"},{"location":"flowise/#flowise","text":"https://flowiseai.com/","title":"flowise"},{"location":"glossary/","text":"Glossary \u00b6 Frequently used acronyms, jargon, and terms Term Definition References Bot ChatGPT fine-tuning GPT Generative Pretrained Transformer HuggingFace Jupyter llama LLM Large Language Model LoRA LoRA (Low-Rank Adaptation of Large Language Models) Mistral Mistral is a decoder-based LM node.js oobabooga OpenAI Python PyTorch RAG retrieval augmented generation React","title":"Glossary"},{"location":"glossary/#glossary","text":"Frequently used acronyms, jargon, and terms Term Definition References Bot ChatGPT fine-tuning GPT Generative Pretrained Transformer HuggingFace Jupyter llama LLM Large Language Model LoRA LoRA (Low-Rank Adaptation of Large Language Models) Mistral Mistral is a decoder-based LM node.js oobabooga OpenAI Python PyTorch RAG retrieval augmented generation React","title":" Glossary"},{"location":"llama/","text":"Llama \u00b6 LLaMA: Open and Efficient Foundation Language Models Retrival-Augmented Generation for Large Language Models: A Survey HuggingFace Llama","title":"Llama"},{"location":"llama/#llama","text":"LLaMA: Open and Efficient Foundation Language Models Retrival-Augmented Generation for Large Language Models: A Survey HuggingFace Llama","title":"Llama"},{"location":"lora/","text":"LoRA (Low-Rank Adaptation of Large Language Models) \u00b6 LoRA Microsoft LoRA","title":"LoRA"},{"location":"lora/#lora-low-rank-adaptation-of-large-language-models","text":"LoRA Microsoft LoRA","title":"LoRA (Low-Rank Adaptation of Large Language Models)"},{"location":"mistral/","text":"Mistral \u00b6 Mistral","title":"Mistral"},{"location":"mistral/#mistral","text":"Mistral","title":"Mistral"},{"location":"ollama/","text":"Ollama \u00b6 ollama.ai llamaindex.ai llamahub.ai","title":"Ollama"},{"location":"ollama/#ollama","text":"ollama.ai llamaindex.ai llamahub.ai","title":"Ollama"},{"location":"oobabooga/","text":"oobabooga text-generation-webui \u00b6 GitHub user oobabooga maintains an open source GPU Affero GPL v3.0 licensed repository called text-generation-webui . [`text-generation-webui( https://github.com/oobabooga/text-generation-webui){target=_blank } is a Gradio web user interface (UI) for Large Language Models. Supports transformers, GPTQ , AWQ , ExLlama v2 (EXL2) , llama.cpp (GGUF) , & other Llama models .","title":"oobabooga"},{"location":"oobabooga/#oobabooga-text-generation-webui","text":"GitHub user oobabooga maintains an open source GPU Affero GPL v3.0 licensed repository called text-generation-webui . [`text-generation-webui( https://github.com/oobabooga/text-generation-webui){target=_blank } is a Gradio web user interface (UI) for Large Language Models. Supports transformers, GPTQ , AWQ , ExLlama v2 (EXL2) , llama.cpp (GGUF) , & other Llama models .","title":" oobabooga text-generation-webui"},{"location":"openai_api/","text":"OpenAI API \u00b6 The OpenAI API is accessed via its Platform","title":"API"},{"location":"openai_api/#openai-api","text":"The OpenAI API is accessed via its Platform","title":"OpenAI API"},{"location":"openai_assistants/","text":"OpenAI Assistants \u00b6 \"Assistants\" are highly similar to GPTs but do not come with a ready-made chatbot, they rely on the OpenAI API and charge the owner of the Assistant for each resposne. The Assistant allows you to select your own model, instructions, description, and knowledge retrieval. Assistants can be run on public facing chatbots. When users interact with the Assistant an API call is sent to OpenAI, a response generated, and returned to the chatbot. The owner of the Assistant will be charged for the number of input and output tokens that the user sends and the API responds with. OpenAI Developer Docs Instructions \u00b6 The prompt which your Assistant will use can be customized to use Code Interpreter, Retrieval, and Function calling. graph TD A[User] --> B[React Material UI Interface] subgraph Application B --> |User Input| C[Node.js Backend] C --> |API Request| D[OpenAI API] D --> |Request for Help| E{ChatGPT Assistant} E --> |Retrieve Info| G[Document Retrieval Module] G --> |PDF, PPTX, HTML| H[Document Storage] I[Code Interpreter] end E --> |Interpret Code| I I --> E H --> G G --> E E --> D D --> |API Response| C C --> |Response Output| B B --> |Response to User| A In this diagram, the ChatGPT Assistant accesses the 'Document Retrieval Module' which in turn retrieves required documents from 'Document Storage' e.g., .PDF , .PPTX , .HTML files. The ChatGPT Assistant can also utilize the Code Interpreter for interpreting code snippets or pieces of logic. Once interpreted, the results are fed back to the ChatGPT assistant. Models \u00b6 as of 12/23/2023: model tokens limit Retrieval additional notes gpt-3.5-turbo 4,096 gpt-3.5-turbo-1106 16,385 gpt-3.5-turbo-16k 16,385 gpt-4 gpt-4-1106-preview Description \u00b6 Knowledge Retrieval \u00b6 Assistants can use up to 20 files <512 MB each or 100 GB total. Each file should have <2,000,000 tokens (~150,000 words or ~300 printed text pages). Creating an assistant programmatically \u00b6 You can write your own Assistant in either node.js , python , or using curl","title":"Assistants"},{"location":"openai_assistants/#openai-assistants","text":"\"Assistants\" are highly similar to GPTs but do not come with a ready-made chatbot, they rely on the OpenAI API and charge the owner of the Assistant for each resposne. The Assistant allows you to select your own model, instructions, description, and knowledge retrieval. Assistants can be run on public facing chatbots. When users interact with the Assistant an API call is sent to OpenAI, a response generated, and returned to the chatbot. The owner of the Assistant will be charged for the number of input and output tokens that the user sends and the API responds with. OpenAI Developer Docs","title":" OpenAI Assistants"},{"location":"openai_assistants/#instructions","text":"The prompt which your Assistant will use can be customized to use Code Interpreter, Retrieval, and Function calling. graph TD A[User] --> B[React Material UI Interface] subgraph Application B --> |User Input| C[Node.js Backend] C --> |API Request| D[OpenAI API] D --> |Request for Help| E{ChatGPT Assistant} E --> |Retrieve Info| G[Document Retrieval Module] G --> |PDF, PPTX, HTML| H[Document Storage] I[Code Interpreter] end E --> |Interpret Code| I I --> E H --> G G --> E E --> D D --> |API Response| C C --> |Response Output| B B --> |Response to User| A In this diagram, the ChatGPT Assistant accesses the 'Document Retrieval Module' which in turn retrieves required documents from 'Document Storage' e.g., .PDF , .PPTX , .HTML files. The ChatGPT Assistant can also utilize the Code Interpreter for interpreting code snippets or pieces of logic. Once interpreted, the results are fed back to the ChatGPT assistant.","title":"Instructions"},{"location":"openai_assistants/#models","text":"as of 12/23/2023: model tokens limit Retrieval additional notes gpt-3.5-turbo 4,096 gpt-3.5-turbo-1106 16,385 gpt-3.5-turbo-16k 16,385 gpt-4 gpt-4-1106-preview","title":"Models"},{"location":"openai_assistants/#description","text":"","title":"Description"},{"location":"openai_assistants/#knowledge-retrieval","text":"Assistants can use up to 20 files <512 MB each or 100 GB total. Each file should have <2,000,000 tokens (~150,000 words or ~300 printed text pages).","title":"Knowledge Retrieval"},{"location":"openai_assistants/#creating-an-assistant-programmatically","text":"You can write your own Assistant in either node.js , python , or using curl","title":"Creating an assistant programmatically"},{"location":"openai_gpts/","text":"GPTs \u00b6 OpenAI GPTs are restricted to paid ChatGPT accounts. GPTs are highly similar to Assistants and use the same foundational models, Instructions, and Knowledge Retrieval. Models \u00b6 gpt4- Instructions \u00b6 Description \u00b6 Knowledge Retrieval \u00b6 10 files 25 mb per file Types of files accepted:","title":"GPTs"},{"location":"openai_gpts/#gpts","text":"OpenAI GPTs are restricted to paid ChatGPT accounts. GPTs are highly similar to Assistants and use the same foundational models, Instructions, and Knowledge Retrieval.","title":"GPTs"},{"location":"openai_gpts/#models","text":"gpt4-","title":"Models"},{"location":"openai_gpts/#instructions","text":"","title":"Instructions"},{"location":"openai_gpts/#description","text":"","title":"Description"},{"location":"openai_gpts/#knowledge-retrieval","text":"10 files 25 mb per file Types of files accepted:","title":"Knowledge Retrieval"},{"location":"openai_playground/","text":"","title":"Playground"},{"location":"rag/","text":"Retrieval Augmented Generation (RAG) \u00b6 graph TD User[(\"User\")] -->|\"Inputs question\"| RAG[\"RAG Model\"] RAG -->|Splits Task| Retrieval[\"Retrieval Module\"] RAG -->|Splits Task| Generation[\"Generation Module\"] Retrieval -->|Retrieves relevant documents| DocDB[\"Document Database\"] DocDB -->|Selects Top-k documents| Encoder[\"Passage Encoder\"] Encoder --> |Sends Encoded Passages| Generation Generation -->|Generates Answer| LLM[\"Language Model (LLM)\"] LLM -->|Presents Generated Answer| UserOutput[(\"User Gets Answer\")] linkStyle default interpolate basis In this graph representation: The User starts the process by inputting a question to the RAG model. The RAG Model breaks down the task into two modules: the Retrieval Module and the Generation Module. The Retrieval Module retrieves relevant documents from the Document Database . These documents are processed by the Passage Encoder which selects the top-k relevant documents and encodes them. The encoded passages are then fed to the Generation Module . The Generation Module , with help from the Language Model (LLM) , takes the user's question and the encoded passages to generate an answer. Finally, the answer generated by the language model is presented to the user as User Gets Answer .","title":"RAG"},{"location":"rag/#retrieval-augmented-generation-rag","text":"graph TD User[(\"User\")] -->|\"Inputs question\"| RAG[\"RAG Model\"] RAG -->|Splits Task| Retrieval[\"Retrieval Module\"] RAG -->|Splits Task| Generation[\"Generation Module\"] Retrieval -->|Retrieves relevant documents| DocDB[\"Document Database\"] DocDB -->|Selects Top-k documents| Encoder[\"Passage Encoder\"] Encoder --> |Sends Encoded Passages| Generation Generation -->|Generates Answer| LLM[\"Language Model (LLM)\"] LLM -->|Presents Generated Answer| UserOutput[(\"User Gets Answer\")] linkStyle default interpolate basis In this graph representation: The User starts the process by inputting a question to the RAG model. The RAG Model breaks down the task into two modules: the Retrieval Module and the Generation Module. The Retrieval Module retrieves relevant documents from the Document Database . These documents are processed by the Passage Encoder which selects the top-k relevant documents and encodes them. The encoded passages are then fed to the Generation Module . The Generation Module , with help from the Language Model (LLM) , takes the user's question and the encoded passages to generate an answer. Finally, the answer generated by the language model is presented to the user as User Gets Answer .","title":"Retrieval Augmented Generation (RAG)"}]}